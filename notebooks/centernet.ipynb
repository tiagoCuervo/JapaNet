{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "centernet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7b5Cy9-6jSf"
      },
      "source": [
        "from comet_ml import Experiment\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, ReLU, Conv2DTranspose, Concatenate, Add, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import sys\n",
        "import importlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6VGA6zt8d1A",
        "outputId": "b5526e69-0f39-4d9a-da96-6f3dcc6608d3"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.7/dist-packages (3.7.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.20.21)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.15.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.9.1)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.0.3)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.0.1)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.12.1)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.58.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa0Wm47U68Eu",
        "outputId": "33d63637-f678-41fa-ae1b-9747c90afe6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/DLProjects/JapaNet\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=\"K5CvVquVZJNg9xfY2ip95FuoD\",\n",
        "    project_name=\"japanet\",\n",
        "    workspace=\"rcofre\",\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/DLProjects/JapaNet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/rcofre/japanet/fe164ee296fb4d69a31f3f129b29aa65\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDtewFt77MzK"
      },
      "source": [
        "from dataloader import IdentifierDataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvKWIlpdBSJa"
      },
      "source": [
        "datasetParams = {\n",
        "    'identifierShufflingBufferSize': 4096,\n",
        "    'classifierShufflingBufferSize': 100,\n",
        "    'batchSize': 32,\n",
        "    'identifierInputHeight': 512,\n",
        "    'identifierInputWidth': 512,\n",
        "    'identifierOutputStride': 4,\n",
        "    'validationFraction': 0.2,\n",
        "    'classifierInputWidth': 64,\n",
        "    'classifierInputHeight': 64\n",
        "}\n",
        "\n",
        "dataset = IdentifierDataset(datasetParams)\n",
        "trainData, validationData = dataset.load()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j_kJc1FxwyP"
      },
      "source": [
        "def convBatchReLU(x, numFilters, kernelSize=3, stride=1, padding=\"same\", upsample=False):\n",
        "    if upsample:\n",
        "        x = Conv2DTranspose(numFilters, kernel_size=kernelSize, strides=stride, padding=padding)(x)\n",
        "    else:    \n",
        "        x = Conv2D(numFilters, kernel_size=kernelSize, strides=stride, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return ReLU()(x)\n",
        "\n",
        "class ResNet:\n",
        "    def __init__(self, inputShape, numBlocks, numBlockFilters, numClasses=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inputShape = inputShape\n",
        "        self.numBlocks = numBlocks\n",
        "        self.numBlockFilters = numBlockFilters\n",
        "        self.numClasses = numClasses\n",
        "\n",
        "    def residualBlock(self, x, numFilters, stride):\n",
        "        y = convBatchReLU(x, numFilters, stride=stride)\n",
        "        y = convBatchReLU(y, numFilters)\n",
        "        if stride == 2 or numFilters != x.shape[-1]:\n",
        "            x = Conv2D(numFilters, 3, strides=stride, padding='same')(x)\n",
        "        return Add()([x, y])\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model.predict(x)\n",
        "\n",
        "    def buildModel(self):\n",
        "        inputLayer = Input(self.inputShape)\n",
        "        x = convBatchReLU(inputLayer, 64, 7, 2)\n",
        "        x = MaxPool2D((3, 3), strides=2, padding=\"same\")(x)\n",
        "        stride = 1\n",
        "        for i in range(4):            \n",
        "            for _ in range(self.numBlocks[i]):\n",
        "                x = self.residualBlock(x, self.numBlockFilters[i], stride=stride)\n",
        "                stride = 1\n",
        "            stride = 2\n",
        "        # At this point the dims are original / 2^5\n",
        "        x = GlobalAveragePooling2D()(x)   # Now the outputs are a 1D vector of size 512\n",
        "        if self.numClasses is not None:\n",
        "            x = Dense(1000)(x)\n",
        "            x = ReLU()(x)\n",
        "            x = Dense(self.numClasses)(x)\n",
        "        return Model(inputLayer, x)\n",
        "\n",
        "class ResNet18(ResNet):\n",
        "    def __init__(self, inputShape, numClasses=None):\n",
        "        super(ResNet18, self).__init__(inputShape, [2] * 4, [64, 128, 256, 512], numClasses)\n",
        "        self.model = self.buildModel()\n",
        "\n",
        "class ResNet34(ResNet):\n",
        "    def __init__(self, inputShape, numClasses=None):\n",
        "        super(ResNet34, self).__init__(inputShape, [3, 4, 6, 3], [64, 128, 256, 512], numClasses)\n",
        "        self.model = self.buildModel()\n",
        "\n",
        "class CenterNet(ResNet):\n",
        "    def __init__(self, inputShape, numBlocks, numBlockFilters, numClasses, inOutRatio=4):\n",
        "        super(CenterNet, self).__init__(inputShape, numBlocks, numBlockFilters, numClasses)\n",
        "        self.numOutputs = numClasses + 4\n",
        "        assert isinstance(inOutRatio, int) and 0 < inOutRatio < 6\n",
        "        self.inOutRatio = inOutRatio\n",
        "        self.model = self.buildModel()\n",
        "\n",
        "    def aggregationBlock(self, x, xSkip, numChannels, stride=2):\n",
        "        x = convBatchReLU(x, numChannels, kernelSize=2, stride=stride, upsample=True)\n",
        "        x = Concatenate()([x, xSkip])\n",
        "        return convBatchReLU(x, numChannels, kernelSize=1, stride=1)\n",
        "\n",
        "    def buildModel(self):\n",
        "        inputLayer = Input(self.inputShape)\n",
        "        xDown = []\n",
        "        x = convBatchReLU(inputLayer, 64, 7, 2)\n",
        "        xDown.append(x)\n",
        "        x = MaxPool2D((3, 3), strides=2, padding=\"same\")(x)\n",
        "        xDown.append(x)\n",
        "        stride = 1\n",
        "        for i in range(4):            \n",
        "            for _ in range(self.numBlocks[i]):\n",
        "                x = self.residualBlock(x, self.numBlockFilters[i], stride=stride)\n",
        "                stride = 1\n",
        "            stride = 2\n",
        "            if i > 0:\n",
        "                xDown.append(x)\n",
        "\n",
        "        x = AveragePooling2D((2, 2))(x) # At this point the dims are original / 2^6\n",
        "        x = convBatchReLU(x, 1024, 1)\n",
        "\n",
        "        for i in range(4, -1, -1):\n",
        "            x = self.aggregationBlock(x, xDown[i], self.numBlockFilters[max(0, i - 1)])\n",
        "            if self.inputShape[0] // x.shape[1]  <= self.inOutRatio:\n",
        "                break\n",
        "        x = Conv2D(self.numOutputs, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "        x = Activation(\"sigmoid\")(x)\n",
        "        return Model(inputLayer, x)\n",
        "\n",
        "    def heatMapLoss(self, target, pred, mask=None):\n",
        "        alpha = 2.\n",
        "        beta = 4.\n",
        "        if mask is None:\n",
        "            mask = K.sign(target[:, :, :, 1])\n",
        "        return -K.sum(target[:, :, :, 0] * ((1 - pred[:, :, :, 0]) ** alpha) * K.log(pred[:, :, :, 0] + 1e-6) + (\n",
        "                    1 - target[:, :, :, 0]) * ((1 - mask) ** beta) * (pred[:, :, :, 0] ** alpha) * K.log(\n",
        "            1 - pred[:, :, :, 0] + 1e-6))\n",
        "\n",
        "\n",
        "    def offsetLoss(self, target, pred, mask=None):\n",
        "        if mask is None:\n",
        "            mask = K.sign(target[:, :, :, 1])\n",
        "        return K.sum(\n",
        "            K.abs(target[:, :, :, 3] - pred[:, :, :, 3] * mask) + K.abs(target[:, :, :, 4] - pred[:, :, :, 4] * mask))\n",
        "\n",
        "\n",
        "    def sizeLoss(self, target, pred, mask=None):\n",
        "        if mask is None:\n",
        "            mask = K.sign(target[:, :, :, 1])\n",
        "        return K.sum(\n",
        "            K.abs(target[:, :, :, 1] - pred[:, :, :, 1] * mask) + K.abs(target[:, :, :, 2] - pred[:, :, :, 2] * mask))\n",
        "\n",
        "    def loss(self, target, pred):\n",
        "        mask = K.sign(target[:, :, :, 1])\n",
        "        N = K.sum(mask)\n",
        "        heatloss = self.heatMapLoss(target, pred, mask)\n",
        "        offsetloss = self.offsetLoss(target, pred, mask)\n",
        "        sizeloss = self.sizeLoss(target, pred, mask)\n",
        "        return (heatloss + 1.0 * offsetloss + 5.0 * sizeloss) / N"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcTzsHeVOqem"
      },
      "source": [
        "centerNet = CenterNet([512, 512, 3], [2] * 4, [64, 128, 256, 512], 1)\n",
        "resNet18 = ResNet18([512, 512, 3], numClasses=4200)\n",
        "resNet34 = ResNet34([512, 512, 3], numClasses=4200)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rKf3qxhOpT6",
        "outputId": "17b37459-6728-43a5-8088-2243a4340b62"
      },
      "source": [
        "imgIdx = 0\n",
        "\n",
        "for image, label in trainData:\n",
        "    x1 = centerNet.predict(tf.reshape(image[imgIdx, :, :, :], (1, 512, 512, 3)))\n",
        "    x2 = resNet18.predict(tf.reshape(image[imgIdx, :, :, :], (1, 512, 512, 3)))\n",
        "    x3 = resNet34.predict(tf.reshape(image[imgIdx, :, :, :], (1, 512, 512, 3)))\n",
        "    break\n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 128, 128, 5)\n",
            "(1, 4200)\n",
            "(1, 4200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMx_OiXdHFZm"
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lrs(epoch):\n",
        "    lr = 0.001\n",
        "    if epoch >= 20: \n",
        "        lr = 0.0002\n",
        "    if epoch >= 40: \n",
        "        lr = 0.0001\n",
        "    if epoch >= 80: \n",
        "        lr = 0.00005\n",
        "    return lr\n",
        "\n",
        "lrSchedule = LearningRateScheduler(lrs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kApyiFl7Mx3p"
      },
      "source": [
        "validationData = validationData.filter(lambda x, y: not tf.reduce_any(tf.math.is_nan(x)) and not tf.reduce_any(tf.math.is_nan(y)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1K2JWpRKmCa"
      },
      "source": [
        "i = 0\n",
        "for image, label in validationData:\n",
        "    tf.debugging.check_numerics(label, message=f\"label in batch {i} is weird\")\n",
        "    tf.debugging.check_numerics(image, message=f\"image in batch {i} is weird\")\n",
        "    i += 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYm9n9xqHw2U",
        "outputId": "8551f078-066d-4f13-c6bf-97b28b9cae2b"
      },
      "source": [
        "def fitCenterNet(model, trainData, valData, numEpochs):\n",
        "    hist = model.fit(\n",
        "        trainData,\n",
        "        epochs = numEpochs,\n",
        "        validation_data=valData,\n",
        "        callbacks = [lrSchedule],\n",
        "        verbose = 1\n",
        "    )\n",
        "    return hist\n",
        "\n",
        "centerNet.model.compile(loss=centerNet.loss, optimizer=Adam(lr=0.001), metrics=[centerNet.heatMapLoss, centerNet.sizeLoss, centerNet.offsetLoss])\n",
        "hist = fitCenterNet(centerNet.model, trainData, validationData, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET WARNING: tensorflow datasets are not currently supported for gradient and activation auto-logging\n",
            "COMET WARNING: tensorflow datasets are not currently supported for gradient and activation auto-logging\n",
            "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "      6/Unknown - 7s 361ms/step - loss: 25.2037 - heatMapLoss: 134699.0820 - sizeLoss: 3787.1140 - offsetLoss: 4388.9404WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0429s vs `on_train_batch_end` time: 0.2658s). Check your callbacks.\n",
            "90/90 [==============================] - 41s 409ms/step - loss: 5.9130 - heatMapLoss: 30847.8547 - sizeLoss: 971.0052 - offsetLoss: 1092.3831 - val_loss: 4.3279 - val_heatMapLoss: 13194.3848 - val_sizeLoss: 2182.1528 - val_offsetLoss: 1487.8538\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 36s 399ms/step - loss: 1.1983 - heatMapLoss: 6723.9676 - sizeLoss: 119.8755 - offsetLoss: 31.0105 - val_loss: 3.5615 - val_heatMapLoss: 16856.8555 - val_sizeLoss: 721.9113 - val_offsetLoss: 446.3233\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 36s 400ms/step - loss: 1.0876 - heatMapLoss: 5988.8525 - sizeLoss: 96.1836 - offsetLoss: 27.6727 - val_loss: 3.8674 - val_heatMapLoss: 20724.0059 - val_sizeLoss: 345.0593 - val_offsetLoss: 214.0085\n",
            "Epoch 4/100\n",
            "26/90 [=======>......................] - ETA: 23s - loss: 0.9976 - heatMapLoss: 5717.5380 - sizeLoss: 89.3138 - offsetLoss: 27.6793"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho3rIJD4ujug"
      },
      "source": [
        "imgIdx = 0\n",
        "for image, label in validationData:\n",
        "    x = centerNet.predict(tf.reshape(image[imgIdx, :, :, :], (1, 512, 512, 3)))\n",
        "    break\n",
        "plt.figure(figsize=(40,10))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(image[imgIdx, :, :, :])\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(x[0, :, :, 0])\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(x[0, :, :, 1] * np.sign(label[imgIdx, :, :, 1])) \n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(x[0, :, :, 2] * np.sign(label[imgIdx, :, :, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}